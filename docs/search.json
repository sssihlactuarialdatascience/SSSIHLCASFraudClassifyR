[{"path":[]},{"path":"/articles/01_data_pre_processing.html","id":"loading-data-and-reducing-dimensionality-of-character-columns","dir":"Articles","previous_headings":"Preparing Input Data","what":"Loading data and Reducing Dimensionality of character columns","title":"Data Pre-processing","text":"remove columns contribute predicting fraud. columns many categories (ex. medical_service_provider_id) top values contributed considered remaining categories taken one category. done since encoding categorical columns bloat data set.","code":"## Considering top 20 unique values from certain columns with large unique values  # medical service provider id mspid <-   claims_dataset %>%   group_by(medical_service_provider_id) %>%   count() %>%   arrange(desc(n))  sum(mspid[1:20, 2]) / sum(mspid[, 2]) #> [1] 0.3289588   \" The code creates data_wo_triggers by copying claims_dataset, replacing medical_service_provider_id values that are not in the top 20 with \\\"Others\\\",and removing columns such as insured_id and primary_diagnosis_code. \" #> [1] \"\\nThe code creates data_wo_triggers by copying claims_dataset, replacing medical_service_provider_id values that are not in the top 20 with \\\"Others\\\",and removing columns such as insured_id and primary_diagnosis_code.\\n\" # removing features that do not contribute in predicting fraud data_wo_triggers <-   claims_dataset %>%   mutate(     medical_service_provider_id =       ifelse(         medical_service_provider_id %in%           mspid[1:20, 1]$medical_service_provider_id,         medical_service_provider_id,         \"Others\"       )   ) %>%   select(     -c(       insured_id,       primary_diagnosis_code,       treatment_start_date,       treatment_end_date,       policy_commencement_date,       policy_termination_date,       claim_reported_date,       claim_count_pa     )   )"},{"path":"/articles/01_data_pre_processing.html","id":"feature-scaling","dir":"Articles","previous_headings":"Preparing Input Data","what":"Feature scaling","title":"Data Pre-processing","text":"Feature scaling important step helps make sure input features scale. machine learning algorithms assume features scale, features big values might given importantance learning process. data set columns amount, number days age normalized.","code":"\" This code normalizes three columns (approved_allowed_amount, no_of_days_stayed, and patient_age) in the data_wo_triggers data frame. The across function applies the same transformation to multiple columns specified with the .cols argument. The mutate function then applies a function which normalizes the values by  subtracting the minimum value from each value and dividing by the range of the column, to each selected column using the .fns argument. \" #> [1] \"\\nThis code normalizes three columns (approved_allowed_amount, no_of_days_stayed, and patient_age) in the data_wo_triggers data frame. The across function applies the same transformation to multiple columns specified with the .cols argument. The mutate function then applies a function which normalizes the values by  subtracting the minimum value from each value and dividing by the range of the column, to each selected column using the .fns argument.\\n\" data_wo_triggers <-   data_wo_triggers %>%   mutate(across(     .cols = c(\"approved_allowed_amount\", \"no_of_days_stayed\", \"patient_age\"),     .fns = ~ (.x - min(.x)) / (max(.x) - min(.x))   ))"},{"path":"/articles/01_data_pre_processing.html","id":"performing-one-hot-encoding-to-non-numeric-columns","dir":"Articles","previous_headings":"Preparing Input Data","what":"Performing One Hot Encoding to Non-numeric columns","title":"Data Pre-processing","text":"data set, several categorical columns directly used machine learning models, since machine learning models usually require numerical inputs. Hence one hot encoding used convert categorical columns numerical format can used machine learning models.","code":"\" The code creates dummy variables for all the  columns in the data_wo_triggers data frame using the dummyVars function from the caret package. The resulting dummy variables are then used to replace the original columns in data_wo_triggers using the predict function. \" #> [1] \"\\nThe code creates dummy variables for all the  columns in the data_wo_triggers data frame using the dummyVars function from the caret package. The resulting dummy variables are then used to replace the original columns in data_wo_triggers using the predict function.\\n\" dmy <- dummyVars(\" ~ .\", data = data_wo_triggers, fullRank = TRUE) data_wo_triggers <-   data.frame(predict(dmy, newdata = data_wo_triggers))"},{"path":"/articles/01_data_pre_processing.html","id":"checking-correlations-of-columns","dir":"Articles","previous_headings":"Preparing Input Data","what":"Checking correlations of columns","title":"Data Pre-processing","text":"identified removed highly correlated variables. ensures variables relevant target variable considered. also helps reducing dimensionality data set improve model’s performance.","code":"\" The code computes the correlation between variables in the 'data_wo_triggers' data frame, ignoring diagonal and upper triangle elements to avoid duplicate computations. It then converts the correlation matrix to a long format data frame using the 'pivot_longer' function, calculates the absolute correlation value, sorts the correlation values in descending order, and stores the resulting data frame in 'corr'. The filter function removes any correlations equal to zero.  \" #> [1] \"\\nThe code computes the correlation between variables in the 'data_wo_triggers' data frame, ignoring diagonal and upper triangle elements to avoid duplicate computations. It then converts the correlation matrix to a long format data frame using the 'pivot_longer' function, calculates the absolute correlation value, sorts the correlation values in descending order, and stores the resulting data frame in 'corr'. The filter function removes any correlations equal to zero.\\n\\n\" corr <- cor(data_wo_triggers)  corr[upper.tri(corr)] = 0 diag(corr) = 0 corr <-   as.data.frame(corr) %>%   rownames_to_column(\"colnames_1\") %>%   pivot_longer(     cols = -colnames_1,     names_to = \"colnames\",     values_to = \"correlation\"   ) %>%   mutate(correlation_1 = abs(correlation)) %>%   arrange(desc(correlation_1)) %>%   filter(correlation_1 != 0)  \" The code creates a vector drop which has the names of the columns with correlation coefficient greater than 0.7 and  it then removes the columns in drop from data_wo_triggers. \" #> [1] \"\\nThe code creates a vector drop which has the names of the columns with correlation coefficient greater than 0.7 and  it then removes the columns in drop from data_wo_triggers.\\n\" #selecting features to drop that are highly correlated drop <-   as.vector(subset(corr, correlation_1 > 0.7 , select = colnames)) data_wo_triggers <-   data_wo_triggers[,!(names(data_wo_triggers) %in% drop$colnames)]"},{"path":"/articles/01_data_pre_processing.html","id":"lasso-regression-to-remove-non-influential-features-in-predicting-fraud","dir":"Articles","previous_headings":"Preparing Input Data > Checking correlations of columns","what":"Lasso regression to remove non-influential features in predicting fraud","title":"Data Pre-processing","text":"case , since large number features, may relevant may little influence target variable, Lasso regression used helps improve model accuracy, reduce overfitting identify important features removing non-influential features.","code":"\" The code uses cross-validation to find the optimal lambda value for a generalized linear model with LASSO regularization, using the glmnet package. It then creates a plot of the mean-squared error for each value of lambda.The code then fits a new model using the optimal lambda value and retrieves the coefficients. It selects the features with non-zero coefficients and orders them by absolute value. If there are more than 30 features with non-zero coefficients, it keeps only the top 30. Finally, it subsets the original data frame to include only the selected features and the target variable 'fraud'. \" #> [1] \"\\nThe code uses cross-validation to find the optimal lambda value for a generalized linear model with LASSO regularization, using the glmnet package. It then creates a plot of the mean-squared error for each value of lambda.The code then fits a new model using the optimal lambda value and retrieves the coefficients. It selects the features with non-zero coefficients and orders them by absolute value. If there are more than 30 features with non-zero coefficients, it keeps only the top 30. Finally, it subsets the original data frame to include only the selected features and the target variable 'fraud'.\\n\"  #perform k-fold cross-validation to find optimal lambda value cv_model <-   cv.glmnet(data.matrix(data_wo_triggers %>%                           select(-c(\"fraud\"))),             data_wo_triggers$fraud,             alpha = 1)  #find optimal lambda value that minimizes test MSE best_lambda = cv_model$lambda.min  #produce plot of test MSE by lambda value plot(cv_model) #find coefficients of best model best_model <-   glmnet(     data.matrix(data_wo_triggers %>% dplyr::select(-c(\"fraud\"))),     data_wo_triggers$fraud,     alpha = 1,     lambda = best_lambda   ) k = as.matrix(coef(best_model)) k = as.data.frame(k[-1, ]) k = k %>% rownames_to_column(\"feature\") names(k)[names(k) == 'k[-1, ]'] <- 'coeff' k = k[k$coeff != 0, ] k = k[order(abs(k$coeff), decreasing = T), ] if (nrow(k) > 30)   k = k[1:30, ] data_wo_triggers = data_wo_triggers[, c(k$feature, \"fraud\")]"},{"path":"/articles/01_data_pre_processing.html","id":"checking-for-class-data-imbalance","dir":"Articles","previous_headings":"Preparing Input Data","what":"Checking for class data Imbalance","title":"Data Pre-processing","text":"Since fraud rare occurrence, proportion fraud cases much lesser non fraud cases. first check presence class imbalance dataset.  evidence suggest existence class data imbalance","code":"\" The code performs class distribution analysis on the data_wo_triggers dataset. It prints the summary statistics of the fraud variable and plots a bar chart of its distribution.The y-axis is set to a range of 0 to 1. \" #> [1] \"\\nThe code performs class distribution analysis on the data_wo_triggers dataset. It prints the summary statistics of the fraud variable and plots a bar chart of its distribution.The y-axis is set to a range of 0 to 1.\\n\"  summary(data_wo_triggers$fraud) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00000 0.00000 0.00000 0.02988 0.00000 1.00000 barplot(   prop.table(table(data_wo_triggers$fraud)),   col = rainbow(3),   ylim = c(0, 1),   main = \"Class Distribution\" )"},{"path":"/articles/01_data_pre_processing.html","id":"splitting-train-and-test-set","dir":"Articles","previous_headings":"Preparing Input Data","what":"Splitting Train and Test set","title":"Data Pre-processing","text":"Splitting dataset training set test set crucial evaluate performance model new, unseen data. training set used train model, test set used evaluate performance.","code":"\" The code creates data_wo_triggers_train and data_wo_triggers_test by randomly sampling 70% of the rows in data_wo_triggers as the Training Set and the remaining 30% as the Test Set. The seed is set to 123 to ensure reproducibility. \" #> [1] \"\\nThe code creates data_wo_triggers_train and data_wo_triggers_test by randomly sampling 70% of the rows in data_wo_triggers as the Training Set and the remaining 30% as the Test Set. The seed is set to 123 to ensure reproducibility.\\n\"  # randomly split data in r set.seed(123) TrainingIndex = sample(seq_len(nrow(data_wo_triggers)), size = 0.7 * nrow(data_wo_triggers)) data_wo_triggers_train <-   data_wo_triggers[TrainingIndex, ] # Training Set data_wo_triggers_test <-   data_wo_triggers[-TrainingIndex, ] # Test Set"},{"path":"/articles/01_data_pre_processing.html","id":"adjusting-data-for-imbalance","dir":"Articles","previous_headings":"Preparing Input Data","what":"Adjusting data for imbalance","title":"Data Pre-processing","text":"seen , class imbalance dataset. Adjusting data imbalance necessary order ensure machine learning models biased towards majority class. used oversampling methods handle data imbalance ensure loss data. brief methods used: ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":"\" A new dataset newData is created using the ADASYN algorithm with data_wo_triggers_train as input. The resulting dataset is assigned to adasyn_wo_triggers_train, and the number of fraud and non-fraud observations is printed.  Similarly, adasyn_wo_triggers_test is created using the ADASYN algorithm with data_wo_triggers_test as input. The resulting dataset is assigned to adasyn_wo_triggers_test, and the number of fraud and non-fraud observations is printed.  Similary it is done using SMOTE,MWMOTE and ROSE. \" #> [1] \"\\nA new dataset newData is created using the ADASYN algorithm with data_wo_triggers_train as input. The resulting dataset is assigned to adasyn_wo_triggers_train, and the number of fraud and non-fraud observations is printed.\\n\\nSimilarly, adasyn_wo_triggers_test is created using the ADASYN algorithm with data_wo_triggers_test as input. The resulting dataset is assigned to adasyn_wo_triggers_test, and the number of fraud and non-fraud observations is printed.\\n\\nSimilary it is done using SMOTE,MWMOTE and ROSE.\\n\""},{"path":"/articles/01_data_pre_processing.html","id":"adasyn","dir":"Articles","previous_headings":"Preparing Input Data > Adjusting data for imbalance","what":"ADASYN","title":"Data Pre-processing","text":"","code":"newData <-   ADAS(X = data_wo_triggers_train,        data_wo_triggers_train$fraud,        K = 5)  adasyn_wo_triggers_train <-   newData$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  adasyn_wo_triggers_train %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     74126 #> 2 1     74110 adasyn_wo_triggers_test <-   ADAS(X = data_wo_triggers_test,        data_wo_triggers_test$fraud,        K = 5)$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  adasyn_wo_triggers_test %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     31804 #> 2 1     31830"},{"path":"/articles/01_data_pre_processing.html","id":"smote","dir":"Articles","previous_headings":"Preparing Input Data > Adjusting data for imbalance","what":"SMOTE","title":"Data Pre-processing","text":"","code":"nrow(data_wo_triggers_train) / sum(data_wo_triggers_train$fraud) #> [1] 33.10307  smote_wo_triggers_train <-   SMOTE(     data_wo_triggers_train,     data_wo_triggers_train$fraud ,     K = 5,     dup_size = 18   )$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  smote_wo_triggers_train %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     74126 #> 2 1     43871 nrow(data_wo_triggers_test) / sum(data_wo_triggers_test$fraud) #> [1] 34.33753  smote_wo_triggers_test <-   SMOTE(     data_wo_triggers_test,     data_wo_triggers_test$fraud ,     K = 5,     dup_size = 18   )$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  smote_wo_triggers_test %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     31804 #> 2 1     18126"},{"path":"/articles/01_data_pre_processing.html","id":"mwmote","dir":"Articles","previous_headings":"Preparing Input Data > Adjusting data for imbalance","what":"MWMOTE","title":"Data Pre-processing","text":"","code":"mwmote_wo_triggers_train <-   mwmote(     dataset = data_wo_triggers_train,     numInstances = nrow(data_wo_triggers_train) - 2 * sum(data_wo_triggers_train$fraud),     classAttr = \"fraud\",     kNoisy = 5,     kMajority = 3,     kMinority = 1,     threshold = 5,     cmax = 2,     cclustering = 3   ) %>%   bind_rows(data_wo_triggers) %>%   mutate(fraud = as.factor(fraud))  mwmote_wo_triggers_train %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud  count #>   <fct>  <int> #> 1 0     105930 #> 2 1      75080 mwmote_wo_triggers_test <-   mwmote(     dataset = data_wo_triggers_test,     numInstances = nrow(data_wo_triggers_test) - 2 * sum(data_wo_triggers_test$fraud),     classAttr = \"fraud\",     kNoisy = 5,     kMajority = 3,     kMinority = 1,     threshold = 5,     cmax = 2,     cclustering = 3   ) %>%   bind_rows(data_wo_triggers) %>%   mutate(fraud = as.factor(fraud))  mwmote_wo_triggers_test %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud  count #>   <fct>  <int> #> 1 0     105930 #> 2 1      34113"},{"path":"/articles/01_data_pre_processing.html","id":"rose","dir":"Articles","previous_headings":"Preparing Input Data > Adjusting data for imbalance","what":"ROSE","title":"Data Pre-processing","text":"vignette, pre-processed claims data set generated train test data sets adjusted data imbalance using methods ADASYN,SMOTE,MWMOTE,ROSE. use vignettes fit machine learning models fraud classification","code":"#chose seed 100 #The N variable is the total number that will be generated #N should essentially be sum of both fraud and non fraud rose_wo_triggers_train <-   ovun.sample(     fraud ~ . ,     data = data_wo_triggers_train,     method = \"over\",     N = (       nrow(data_wo_triggers_train) - sum(data_wo_triggers_train$fraud)     ) * 2,     seed = 100   )$data %>%   mutate(fraud = as.factor(fraud))  table(rose_wo_triggers_train$fraud) #>  #>     0     1  #> 74126 74126  barplot(   prop.table(table(rose_wo_triggers_train$fraud)),   col = rainbow(3),   ylim = c(0, 1),   main = \"Class Distribution\" ) #chose seed 100 #The N variable is the total number that will be generated #N should essentially be sum of both fraud and non fraud rose_wo_triggers_test <-   ovun.sample(     fraud ~ . ,     data = data_wo_triggers_test,     method = \"over\",     N = (       nrow(data_wo_triggers_test) - sum(data_wo_triggers_test$fraud)     ) * 2,     seed = 100   )$data %>%   mutate(fraud = as.factor(fraud))  table(rose_wo_triggers_test$fraud) #>  #>     0     1  #> 31804 31804  barplot(   prop.table(table(rose_wo_triggers_test$fraud)),   col = rainbow(3),   ylim = c(0, 1),   main = \"Class Distribution\" )"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"mapping-triggers-to-claims-data","dir":"Articles","previous_headings":"","what":"Mapping triggers to claims data","title":"Mapping Triggers to Data","text":"trigger maps add additional columns 0’s 1’s dataset. “1”represents flag raised trigger.","code":""},{"path":"/articles/02_mapping_triggers_to_data.html","id":"claim_amount_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"claim_amount_trigger_map","title":"Mapping Triggers to Data","text":"typically predetermined amount agreed upon insurer medical service provider procedure, particularly cashless claim processing. claim amount exceeds established procedure-specific amount, raise flag.","code":"data <-   trigger_data %>%   janitor::clean_names() %>%   dplyr::select(primary_procedure_code, package_amount_trigger) data_w_triggers <-   claim_amount_trigger_map(     claims_file = claims_dataset,     claim_paid_field = \"approved_allowed_amount\",     triggers_file = data,     procedure_code = \"primary_procedure_code\",     procedure_amount_field = \"package_amount_trigger\"   ) summary(data_w_triggers$claim_amount_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.0000  1.0000  1.0000  0.9962  1.0000  1.0000"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"hosp_days_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"hosp_days_trigger_map","title":"Mapping Triggers to Data","text":"specific number days claimant can admitted hospital deemed reasonable procedure. actual number days spent hospital exceeds reasonable duration given procedure, function raise flag.","code":"data <-   trigger_data %>%   janitor::clean_names() %>%   dplyr::select(primary_procedure_code,                 admission_days_trigger) data_w_triggers <-   hosp_days_trigger_map(     claims_file = data_w_triggers,     no_of_days_stayed = \"no_of_days_stayed\",     triggers_file = data,     procedure_code = \"primary_procedure_code\",     admission_days_trigger = \"admission_days_trigger\"   ) summary(data_w_triggers$hosp_days_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.0000  1.0000  1.0000  0.7871  1.0000  1.0000"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"age_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"age_trigger_map","title":"Mapping Triggers to Data","text":"triggers file includes age ranges considered reasonable undergoing particular medical procedure. function raises flag claimants whose age falls outside range. order function operate correctly, age must consistently specified claims_file triggers_file.","code":"data <-   trigger_data %>%   janitor::clean_names() %>%   dplyr::select(lower_age_limit, upper_age_limit, primary_procedure_code)  data$primary_procedure_code <-   as.character(data$primary_procedure_code)  data_w_triggers <-   age_trigger_map(     claims_file = data_w_triggers,     age_column_name = \"patient_age\",     triggers_file = data,     lower_age_limit = \"lower_age_limit\",     upper_age_limit = \"upper_age_limit\",     procedure_code = \"primary_procedure_code\"   ) summary(data_w_triggers$age_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>       0       0       0       0       0       0"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"gender_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"gender_trigger_map","title":"Mapping Triggers to Data","text":"Certain medical procedures specific particular gender. procedure performed claimant wrong gender, function raises flag. instance, gynecological procedure performed male claimant trigger warning. enable function operate correctly, gender must specified consistently claims_file triggers_file.","code":"data <-   trigger_data %>%   janitor::clean_names() %>%   dplyr::select(primary_procedure_code, gender_trigger)  data_w_triggers <-   gender_trigger_map(     claims_file = data_w_triggers,     gender_column_name = \"gender_code\",     triggers_file = data,     procedure_code = \"primary_procedure_code\",     gender_trigger = \"gender_trigger\"   ) summary(data_w_triggers$gender_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00000 0.00000 0.00000 0.01805 0.00000 1.00000"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"claim_count_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"claim_count_trigger_map","title":"Mapping Triggers to Data","text":"frequency receiving particular medical treatment typically limited policyholders, depending nature treatment. policyholder undergone particular treatment unreasonably high number times, may investigated fraud. function detects policyholders received given treatment excessively raises flag.","code":"data <-   trigger_data %>%   janitor::clean_names() %>%   dplyr::select(primary_procedure_code, claim_count_trigger)  data_w_triggers <-   claim_count_trigger_map(     claim_count = data_w_triggers,     claim_count_pa = \"claim_count_pa\",     claim_count_trigger_file = data,     procedure_code_field = \"primary_procedure_code\",     claim_count_trigger = \"claim_count_trigger\"   ) summary(data_w_triggers$claim_count_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.0000  0.0000  0.0000  0.4156  1.0000  1.0000"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"close_prox_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"close_prox_trigger_map","title":"Mapping Triggers to Data","text":"claim close proximity treatment start date close policy commencement date. function raise flag claims.","code":"data <-   trigger_data %>%   janitor::clean_names() %>%   dplyr::select(primary_procedure_code, close_prox_days)  data_w_triggers <-   close_prox_trigger_map(     claims_file = data_w_triggers,     treatment_start_date = \"treatment_start_date\",     policy_commencement_date = \"policy_commencement_date\",     triggers_file = data,     procedure_code = \"primary_procedure_code\",     close_prox_days = \"close_prox_days\"   ) summary(data_w_triggers$close_prox_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00000 0.00000 0.00000 0.03352 0.00000 1.00000"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"treatment_date_validity_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"treatment_date_validity_trigger_map","title":"Mapping Triggers to Data","text":"policy commencement termination date within claim event(treatment) occur. treatment date outside dates, raise flag.","code":"data_w_triggers <-   treatment_date_validity_trigger_map(     claims_file = data_w_triggers,     treatment_start_date_field = \"treatment_start_date\",     policy_commencement_date_field = \"policy_commencement_date\",     policy_termination_date_field = \"policy_termination_date\"   ) summary(data_w_triggers$treatment_date_validity_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>       0       0       0       0       0       0"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"claim_reported_delay_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"claim_reported_delay_trigger_map","title":"Mapping Triggers to Data","text":"policy treatment start date treatment end date. claim reported within permissible days treatment end date (discharge date). claim reported date outside permissible limit raise flag.","code":"data_w_triggers <-   claim_reported_delay_trigger_map(     claims_file = data_w_triggers,     treatment_end_date_field = \"treatment_end_date\",     claim_reported_date_field = \"claim_reported_date\",     claim_delay_days = 15   ) summary(data_w_triggers$claim_reported_delay_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00000 0.00000 0.00000 0.08356 0.00000 1.00000"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"hospital_empanelled_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"hospital_empanelled_trigger_map","title":"Mapping Triggers to Data","text":"Insurers typically select hospitals serve policyholders process known empanelment. process, insurer verifies hospital necessary facilities agrees upon tariff treatment. hospital included list empaneled hospitals, flag raised.","code":"data_w_triggers <-   hospital_empanelled_trigger_map(     claims_file = data_w_triggers,     hospital_id_field = \"medical_service_provider_id\",     empanelled_hospitals_list = hospital_list,     empanelled_hospital_id = \"hosp_id\"   ) summary(data_w_triggers$hospital_empanelled_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>       0       0       0       0       0       0"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"hospital_distance_trigger_map","dir":"Articles","previous_headings":"Mapping triggers to claims data","what":"hospital_distance_trigger_map","title":"Mapping Triggers to Data","text":"reasonable anticipate policyholder receive treatment nearest hospital. distance policyholder’s residence location hospital location exceeds predetermined threshold, function raise flag.","code":"data_w_triggers <-   hospital_distance_trigger_map(     claims_file = data_w_triggers,     residence_location_field = \"residence_location\",     hospital_location_field = \"hospital_location\",     hospital_distance_file = location_distance,     residence_location_map = \"location_1\",     hospital_location_map = \"location_2\",     hospital_distance_field = \"distance\",     distance_threshold = 100   ) summary(data_w_triggers$hospital_distance_flag) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.0000  0.0000  0.0000  0.2882  1.0000  1.0000"},{"path":[]},{"path":"/articles/02_mapping_triggers_to_data.html","id":"reducing-dimensionality-of-character-columns","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Reducing dimensionality of character columns","title":"Mapping Triggers to Data","text":"removed columns contribute predicting fraud. columns many categories top values contributed considered remaining categories taken one category. done since encoding categorical columns bloat data set.","code":"## Considering top 20 unique values from certain columns with large unique values  # medical service provider id mspid <-   data_w_triggers %>%   group_by(medical_service_provider_id) %>%   count() %>%   arrange(desc(n))  sum(mspid[1:20, 2]) / sum(mspid[, 2]) #> [1] 0.3289588  data_w_triggers <-   data_w_triggers %>%   mutate(     medical_service_provider_id =       ifelse(         medical_service_provider_id %in% mspid[1:20, 1]$medical_service_provider_id,         medical_service_provider_id,         \"Others\"       )   ) %>%   dplyr::select(     -c(       insured_id,       primary_diagnosis_code,       treatment_start_date,       treatment_end_date,       policy_commencement_date,       policy_termination_date,       claim_reported_date     )   )"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"performing-onehot-encoding-to-non-numeric-columns","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Performing OneHot Encoding to Non-numeric columns","title":"Mapping Triggers to Data","text":"dataset, several categorical columns directly used machine learning models, since machine learning models usually require numerical inputs. Hence one hot encoding used convert categorical columns numerical format can used machine learning models.","code":"dmy <- dummyVars(\" ~ .\", data = data_w_triggers, fullRank = TRUE) data_w_triggers <-   data.frame(predict(dmy, newdata = data_w_triggers))"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"removing-features-with-sd-0-and-removing-trigger-information-features","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Removing features with SD 0 and removing trigger information features","title":"Mapping Triggers to Data","text":"columns used generate flag columns longer needed. Hence removed dataset.","code":"drop1 = c(   \"package_amount_trigger\",   \"lower_age_limit\",   \"upper_age_limit\",   \"age_flag\",   \"gender_triggerFemale\",   \"claim_count_trigger\",   \"close_prox_days\",   \"hospital_empanelled_flag\",   \"treatment_date_validity_flag\" )  data_w_triggers <-   data_w_triggers %>%   select(-c(drop1))"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"feature-scaling","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Feature scaling","title":"Mapping Triggers to Data","text":"Feature scaling important step helps make sure input features scale. ’s important machine learning algorithms assume features scale, features big values might given importantance learning process.","code":"data_w_triggers <-   data_w_triggers %>%   mutate(across(     .cols = c(       \"approved_allowed_amount\",       \"no_of_days_stayed\",       \"patient_age\",       \"claim_count_pa\",       \"claim_duration_days\",       \"distance\"     ),     .fns = ~ (.x - min(.x)) / (max(.x) - min(.x))   ))"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"checking-for-class-data-imbalance","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Checking for class data Imbalance","title":"Mapping Triggers to Data","text":"Since fraud rare occurrence, proportion fraud cases much lesser non fraud cases. first check presence class imbalance dataset.","code":"summary(data_w_triggers$fraud) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00000 0.00000 0.00000 0.02988 0.00000 1.00000 barplot(   prop.table(table(data_w_triggers$fraud)),   col = rainbow(3),   ylim = c(0, 1),   main = \"Class Distribution\" )"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"splitting-train-and-test-data","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Splitting train and test data","title":"Mapping Triggers to Data","text":"Splitting dataset training set test set crucial evaluate performance model new, unseen data. training set used train model, test set used evaluate performance.","code":"set.seed(123) data_w_triggers =    data_w_triggers[, c(   \"medical_service_provider_idhospital32\",   \"medical_service_provider_idhospital185\",   \"medical_service_provider_idhospital58\",   \"primary_procedure_codeM100068\",   \"medical_service_provider_idhospital118\",   \"medical_service_provider_idhospital31\",   \"hospital_locationlocation22\",   \"medical_service_provider_idhospital181\",   \"medical_service_provider_idhospital247\",   \"medical_service_provider_idhospital14\",   \"medical_service_provider_idhospital71\",   \"hospital_locationlocation20\",   \"patient_age\",   \"medical_service_provider_idhospital127\",   \"medical_service_provider_idhospital49\",   \"hospital_locationlocation15\",   \"medical_service_provider_idhospital188\",   \"hospital_locationlocation12\",   \"hospital_locationlocation13\",   \"primary_procedure_codeM100008\",   \"hospital_locationlocation19\",   \"hospital_locationlocation14\",   \"primary_procedure_codeM100009\",   \"primary_procedure_codeM700004\",   \"no_of_days_stayed\",   \"residence_locationlocation5\",   \"hospital_locationlocation5\",   \"approved_allowed_amount\",   \"hospital_locationlocation17\",   \"primary_procedure_codeU100\",   \"fraud\",   \"claim_amount_flag\",   \"hosp_days_flag\",   \"gender_flag\",   \"claim_count_flag\",   \"close_prox_flag\",   \"distance\",   \"hospital_distance_flag\",   \"claim_duration_days\",   \"claim_reported_delay_flag\" )]  # randomly split data in r TrainingIndex = sample(seq_len(nrow(data_w_triggers)), size = 0.7 * nrow(data_w_triggers)) data_w_triggers_train <-   data_w_triggers[TrainingIndex, ] # Training Set data_w_triggers_test <- data_w_triggers[-TrainingIndex, ] # Test Set"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"adjusting-data-for-imbalance","dir":"Articles","previous_headings":"Preparing Input data with triggers","what":"Adjusting data for imbalance","title":"Mapping Triggers to Data","text":"seen , class imbalance dataset. Adjusting data imbalance necessary order ensure machine learning models biased towards majority class. used oversampling methods handle data imbalance ensure loss data.","code":""},{"path":"/articles/02_mapping_triggers_to_data.html","id":"adasyn","dir":"Articles","previous_headings":"Preparing Input data with triggers > Adjusting data for imbalance","what":"ADASYN","title":"Mapping Triggers to Data","text":"","code":"newData <-   ADAS(X = data_w_triggers_train,        data_w_triggers_train$fraud,        K = 5)  adasyn_w_triggers_train <-   newData$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  adasyn_w_triggers_train %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     74126 #> 2 1     74088 adasyn_w_triggers_test <-   ADAS(X = data_w_triggers_test,        data_w_triggers_test$fraud,        K = 5)$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  adasyn_w_triggers_test %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     31804 #> 2 1     31844"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"smote","dir":"Articles","previous_headings":"Preparing Input data with triggers > Adjusting data for imbalance","what":"SMOTE","title":"Mapping Triggers to Data","text":"","code":"nrow(data_w_triggers_train) / sum(data_w_triggers_train$fraud) #> [1] 33.10307  smote_w_triggers_train <-   SMOTE(     data_w_triggers_train,     data_w_triggers_train$fraud ,     K = 5,     dup_size = 18   )$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  smote_w_triggers_train %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     74126 #> 2 1     43871 nrow(data_w_triggers_test) / sum(data_w_triggers_test$fraud) #> [1] 34.33753  smote_w_triggers_test <-   SMOTE(     data_w_triggers_test,     data_w_triggers_test$fraud ,     K = 5,     dup_size = 18   )$data %>%   dplyr::select(-c(\"class\")) %>%   mutate(fraud = as.factor(fraud))  smote_w_triggers_test %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud count #>   <fct> <int> #> 1 0     31804 #> 2 1     18126"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"mwmote","dir":"Articles","previous_headings":"Preparing Input data with triggers > Adjusting data for imbalance","what":"MWMOTE","title":"Mapping Triggers to Data","text":"","code":"mwmote_w_triggers_train <-   mwmote(     dataset = data_w_triggers_train,     numInstances = nrow(data_w_triggers_train) - 2 * sum(data_w_triggers_train$fraud),     classAttr = \"fraud\",     kNoisy = 5,     kMajority = 3,     kMinority = 1,     threshold = 5,     cmax = 2,     cclustering = 3   ) %>%   bind_rows(data_w_triggers) %>%   mutate(fraud = as.factor(fraud))  mwmote_w_triggers_train %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud  count #>   <fct>  <int> #> 1 0     105930 #> 2 1      75080 mwmote_w_triggers_test <-   mwmote(     dataset = data_w_triggers_test,     numInstances = nrow(data_w_triggers_test) - 2 * sum(data_w_triggers_test$fraud),     classAttr = \"fraud\",     kNoisy = 5,     kMajority = 3,     kMinority = 1,     threshold = 5,     cmax = 2,     cclustering = 3   ) %>%   bind_rows(data_w_triggers) %>%   mutate(fraud = as.factor(fraud))  mwmote_w_triggers_test %>%   group_by(fraud) %>%   summarise(count = n()) %>%   print() #> # A tibble: 2 × 2 #>   fraud  count #>   <fct>  <int> #> 1 0     105930 #> 2 1      34113"},{"path":"/articles/02_mapping_triggers_to_data.html","id":"rose","dir":"Articles","previous_headings":"Preparing Input data with triggers > Adjusting data for imbalance","what":"ROSE","title":"Mapping Triggers to Data","text":"","code":"#chose seed 100 #The N variable is the total number that will be generated #N should essentially be sum of both fraud and non fraud rose_w_triggers_train <-   ovun.sample(     fraud ~ . ,     data = data_w_triggers_train,     method = \"over\",     N = (       nrow(data_w_triggers_train) - sum(data_w_triggers_train$fraud)     ) * 2,     seed = 100   )$data %>%   mutate(fraud = as.factor(fraud))  table(rose_w_triggers_train$fraud) #>  #>     0     1  #> 74126 74126  barplot(   prop.table(table(rose_w_triggers_train$fraud)),   col = rainbow(3),   ylim = c(0, 1),   main = \"Class Distribution\" ) #chose seed 100 #The N variable is the total number that will be generated #N should essentially be sum of both fraud and non fraud rose_w_triggers_test <-   ovun.sample(     fraud ~ . ,     data = data_w_triggers_test,     method = \"over\",     N = (nrow(data_w_triggers_test) - sum(data_w_triggers_test$fraud)) * 2,     seed = 100   )$data %>%   mutate(fraud = as.factor(fraud))  table(rose_w_triggers_test$fraud) #>  #>     0     1  #> 31804 31804  barplot(   prop.table(table(rose_w_triggers_test$fraud)),   col = rainbow(3),   ylim = c(0, 1),   main = \"Class Distribution\" )"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"improving-fit-of-a-decision-tree-model","dir":"Articles","previous_headings":"","what":"Improving fit of a decision tree model","title":"Fraud Classification with Decision Trees","text":"One can add triggers standard claims dataset improve model’s predictability fraud. illustrate using decision tree model vignette. data pre-processing vignette, treated data imbalance claims data using 4 different types data imbalance techniques - ADASYN, SMOTE, MWMOTE ROSE. decision tree algorithm supervised learning algorithm can used classification regression tasks. scenario using binary classification problem. decision tree algorithm creates tree-like structure helps make predictions based certain characteristics data. keeps dividing data smaller groups based important features, finds simple answer. tree can used predict new data.","code":""},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"importing-required-libraries","dir":"Articles","previous_headings":"","what":"Importing required libraries","title":"Fraud Classification with Decision Trees","text":"","code":"library(dplyr) library(rpart) library(pROC) library(caret) library(PRROC) library(rpart.plot) library(tidyr) library(stringr) library(ggplot2) options(scipen=999)"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"creating-decision-tree-model-function","dir":"Articles","previous_headings":"","what":"Creating decision tree model function","title":"Fraud Classification with Decision Trees","text":"create function implementing decision tree model order easily apply various data sets. function takes two arguments: train data set test data set response variable “fraud” variables considered predictor variables. Gini index used default parameter measure quality split. Overall, function performs binary classification predict fraud non-fraud using decision tree evaluates performance using various metrics. F2 score used appropriate metric compare model-fit results. want improve identification fraud. function also provides visual representation decision tree.","code":"decision_tree <- function(data_train, data_test) {   tree <-     rpart(fraud ~ .,           data = data_train,           method = 'class',           minsplit = 5)   tree.pred <-     predict(tree, data_test %>% select(-c(\"fraud\")), type = \"prob\")[, 2]   roc_obj <- roc(data_test$fraud, tree.pred)   threshold <- coords(roc_obj, \"best\")[[1]]   tree.pred <- ifelse(tree.pred > threshold, 1, 0)      c <-     confusionMatrix(as.factor(tree.pred),                     data_test$fraud,                     mode = \"everything\",                     positive = \"1\")   c <-     rbind(c,           c(             method = paste0(\"DT \", deparse(substitute(data_train))),             c$overall[1],             c$byClass[c(1, 2, 5, 6, 7)],             roc_obj$auc,             pr.curve(tree.pred, data_test$fraud)$auc.integral           ))   c = as.data.frame(c[-1, ])      colnames(c)[1] = \"Method+dataset\"   colnames(c)[8] = \"ROC-AUC\"   colnames(c)[9] = \"PR-AUC\"      c <-     c %>%     mutate(       across(.cols = -`Method+dataset`, .fns = as.numeric),       trigger = ifelse(stringr::str_detect(`Method+dataset`, \"wo\"), \"N\", \"Y\")     ) %>%     separate(`Method+dataset`, c(\"method\", \"NA_1\"), \" \", remove = TRUE) %>%     separate(NA_1, c(\"imbalance\", NA, NA)) %>%      mutate(`F2 Score` = ((1 + 2^2) * Precision * Recall) / (2^2 * Precision + Recall)) %>%      select(method, imbalance,trigger ,`F2 Score`)      rpart.plot(tree, extra = 101)   return(c) }"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"applying-the-function-to-the-datasets","dir":"Articles","previous_headings":"","what":"Applying the function to the datasets","title":"Fraud Classification with Decision Trees","text":"function now applied datasets adjusted data imbalance using ADASYN, SMOTE, MWMOTE ROSE. brief methods: ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":""},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"adasyn","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ADASYN","title":"Fraud Classification with Decision Trees","text":"","code":"adasyn_wo_triggers <-   decision_tree(adasyn_wo_triggers_train,                 adasyn_wo_triggers_test) adasyn_w_triggers <-   decision_tree(adasyn_w_triggers_train,                 adasyn_w_triggers_test)"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"smote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"SMOTE","title":"Fraud Classification with Decision Trees","text":"","code":"smote_wo_triggers <-    decision_tree(smote_wo_triggers_train,                 smote_wo_triggers_test) smote_w_triggers <-   decision_tree(smote_w_triggers_train,                 smote_w_triggers_test)"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"mwmote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"MWMOTE","title":"Fraud Classification with Decision Trees","text":"","code":"mwmote_wo_triggers <-    decision_tree(mwmote_wo_triggers_train,                 mwmote_wo_triggers_test) mwmote_w_triggers <-   decision_tree(mwmote_w_triggers_train,                 mwmote_w_triggers_test)"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"rose","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ROSE","title":"Fraud Classification with Decision Trees","text":"","code":"rose_wo_triggers <-    decision_tree(rose_wo_triggers_train,                 rose_wo_triggers_test) rose_w_triggers <-   decision_tree(rose_w_triggers_train,                 rose_w_triggers_test)"},{"path":"/articles/03_fraud_classification_decision_trees.html","id":"results-comparison","dir":"Articles","previous_headings":"","what":"Results comparison","title":"Fraud Classification with Decision Trees","text":"can seen charts, models trigger fields shown better predictability compared without triggers.","code":"bind_rows(   adasyn_wo_triggers,   adasyn_w_triggers,   smote_wo_triggers,   smote_w_triggers,   mwmote_wo_triggers,   mwmote_w_triggers,   rose_wo_triggers,   rose_w_triggers ) %>%   select(imbalance, trigger, everything()) %>%    ggplot() +   geom_bar(aes(x = trigger, y = `F2 Score`, fill = trigger), stat='identity') +   facet_wrap(~imbalance)"},{"path":"/articles/04_fraud_classification_glm.html","id":"improving-fit-of-a-generalized-linear-model-glm","dir":"Articles","previous_headings":"","what":"Improving fit of a Generalized Linear Model (GLM)","title":"Fraud Classification with GLM","text":"One can add triggers standard claims dataset improve model’s predictability fraud. illustrate using glm vignette. data pre-processing vignette, treated data imbalance claims data using 4 different types data imbalance techniques - ADASYN, SMOTE, MWMOTE ROSE. GLM supervised machine learning algorithm used regression classification problems. scenario using binary classification problem. works choosing distribution fits data, selecting link function transform response variable, estimating model parameters, making predictions new data. assumes linear relationship predictors response variable.","code":""},{"path":"/articles/04_fraud_classification_glm.html","id":"importing-required-libraries","dir":"Articles","previous_headings":"","what":"Importing required libraries","title":"Fraud Classification with GLM","text":"","code":"library(dplyr) library(rpart) library(pROC) library(caret) library(PRROC) library(tidyr) library(stringr) library(ggplot2) options(scipen=999)"},{"path":"/articles/04_fraud_classification_glm.html","id":"creating-glm-model-function","dir":"Articles","previous_headings":"","what":"Creating GLM model function","title":"Fraud Classification with GLM","text":"create function implementing GLM model order easily apply various datasets. function takes two arguments: train dataset test dataset response variable “fraud” variables considered predictor variables. Overall function fits GLM using binomial family logit link function binary classification fraud non-fraud evaluates performance using various metrics. F2 score used appropriate metric compare model-fit results. want improve identification fraud.","code":"glm_function <- function(data_train, data_test) {   # Fit the GLM model   fit <-     glm(fraud ~ ., data = data_train, family = binomial(link = \"logit\"))      # Testing Set   test_prob <-     predict(fit,             newdata = data_test %>% dplyr::select(-c(\"fraud\")),             type = \"response\")      # Get the ROC curve and calculate the ROC AUC   roc_obj <- roc(data_test$fraud, test_prob)   roc_auc <- auc(roc_obj)      # Get the PR curve and calculate the PR AUC   pr_obj <- pr.curve(data_test$fraud, test_prob)   pr_auc <- pr_obj$auc.integral      # Set the threshold based on the optimal ROC curve threshold   threshold <- coords(roc_obj, \"best\")[[1]]   model_glm_test_pred <- ifelse(test_prob > threshold, 1, 0)      # Confusion Matrix   c1 <-     confusionMatrix(       data_test$fraud,       as.factor(model_glm_test_pred),       mode = \"everything\",       positive = \"1\"     )   c <-     rbind(c1, c(       paste0(\"GLM \", deparse(substitute(data_train))),       c1$overall[1],       c1$byClass[c(1, 2, 5, 6, 7)],       roc_auc,       pr_auc     ))   c <- as.data.frame(c[-1, ])      colnames(c)[1] = \"Method+dataset\"   colnames(c)[8] = \"ROC-AUC\"   colnames(c)[9] = \"PR-AUC\"      c <-     c %>%     mutate(       across(.cols = -`Method+dataset`, .fns = as.numeric),       trigger = ifelse(stringr::str_detect(`Method+dataset`, \"wo\"), \"N\", \"Y\")     ) %>%     separate(`Method+dataset`, c(\"method\", \"NA_1\"), \" \", remove = TRUE) %>%     separate(NA_1, c(\"imbalance\", NA, NA)) %>%      mutate(`F2 Score` = ((1 + 2^2) * Precision * Recall) / (2^2 * Precision + Recall)) %>%      select(method, imbalance,trigger ,`F2 Score`)      broom::tidy(fit)      return(c)    }"},{"path":"/articles/04_fraud_classification_glm.html","id":"applying-the-function-to-the-datasets","dir":"Articles","previous_headings":"","what":"Applying the function to the datasets","title":"Fraud Classification with GLM","text":"function now applied datasets adjusted data imbalance using ADASYN, SMOTE, MWMOTE ROSE. brief methods: ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":""},{"path":"/articles/04_fraud_classification_glm.html","id":"adasyn","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ADASYN","title":"Fraud Classification with GLM","text":"","code":"adasyn_wo_triggers <-    glm_function(adasyn_wo_triggers_train,                 adasyn_wo_triggers_test) adasyn_w_triggers <-   glm_function(adasyn_w_triggers_train,                 adasyn_w_triggers_test)"},{"path":"/articles/04_fraud_classification_glm.html","id":"smote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"SMOTE","title":"Fraud Classification with GLM","text":"","code":"smote_wo_triggers <-    glm_function(smote_wo_triggers_train,                 smote_wo_triggers_test) smote_w_triggers <-   glm_function(smote_w_triggers_train,                 smote_w_triggers_test)"},{"path":"/articles/04_fraud_classification_glm.html","id":"mwmote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"MWMOTE","title":"Fraud Classification with GLM","text":"","code":"mwmote_wo_triggers <-    glm_function(mwmote_wo_triggers_train,                 mwmote_wo_triggers_test) mwmote_w_triggers <-   glm_function(mwmote_w_triggers_train,                 mwmote_w_triggers_test)"},{"path":"/articles/04_fraud_classification_glm.html","id":"rose","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ROSE","title":"Fraud Classification with GLM","text":"","code":"rose_wo_triggers <-    glm_function(rose_wo_triggers_train,                 rose_wo_triggers_test) rose_w_triggers <-   glm_function(rose_w_triggers_train,                 rose_w_triggers_test)"},{"path":"/articles/04_fraud_classification_glm.html","id":"results-comparison","dir":"Articles","previous_headings":"","what":"Results comparison","title":"Fraud Classification with GLM","text":"can seen charts, models trigger fields shown better predictability compared without triggers.","code":"bind_rows(   adasyn_wo_triggers,   adasyn_w_triggers,   smote_wo_triggers,   smote_w_triggers,   mwmote_wo_triggers,   mwmote_w_triggers,   rose_wo_triggers,   rose_w_triggers ) %>%   select(imbalance, trigger, everything()) %>%    ggplot() +   geom_bar(aes(x = trigger, y = `F2 Score`, fill = trigger), stat='identity') +   facet_wrap(~imbalance)"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"improving-fit-of-a-decision-tree-model","dir":"Articles","previous_headings":"","what":"Improving fit of a decision tree model","title":"Fraud Classification with Naive Bayes","text":"One can add triggers standard claims dataset improve model’s predictability fraud. illustrate using decision tree model vignette. data pre-processing vignette, treated data imbalance claims data using 4 different types data imbalance techniques - ADASYN, SMOTE, MWMOTE ROSE. Naive Bayes algorithm supervised machine learning algorithm used classification problems based probability theory. scenario using binary classification problem. works calculating probability class based training data, probability feature given class, combining get probability class given evidence. algorithm selects class highest probability predicted class. Naive Bayes assumes features independent .","code":""},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"importing-required-libraries","dir":"Articles","previous_headings":"","what":"Importing required libraries","title":"Fraud Classification with Naive Bayes","text":"","code":"library(dplyr) library(rpart) library(pROC) library(caret) library(naivebayes) library(e1071) library(PRROC) library(tidyr) library(stringr) library(ggplot2) options(scipen=999)"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"creating-naive-bayes-model-function","dir":"Articles","previous_headings":"","what":"Creating Naive Bayes model function","title":"Fraud Classification with Naive Bayes","text":"create function implementing Naive Bayes model order easily apply various datasets. function takes two arguments: train dataset test dataset. response variable “fraud” variables considered predictor variables. Overall function fits Naive Bayes model binary classification fraud non-fraud evaluates performance using various metrics. F2 score used appropriate metric compare model-fit results. want improve identification fraud.","code":"naive_bayes_classifier <- function(data_train, data_test) {   # fit model   fit <- naiveBayes(fraud ~ ., data = data_train)      # summarize the fit   #print(fit)      # make predictions on test set   test_prob <-     predict(fit,             newdata = data_test %>% dplyr::select(-c(\"fraud\")),             type = \"raw\")[, 2]      # calculate ROC AUC   roc_auc <- roc(data_test$fraud, test_prob)$auc      # calculate PR AUC   pr_auc <- pr.curve(data_test$fraud, test_prob)$auc.integral      # set threshold based on optimal ROC curve threshold   threshold <- coords(roc(data_test$fraud, test_prob), \"best\")[[1]]      # make predictions based on threshold   model_nb_test_pred <- ifelse(test_prob > threshold, 1, 0)      # confusion matrix   c1 <-     confusionMatrix(       data_test$fraud,       as.factor(model_nb_test_pred),       mode = \"everything\",       positive = \"1\"     )   c <-     rbind(c1, c(       paste0(\"NB \", deparse(substitute(data_train))),       c1$overall[1],       c1$byClass[c(1, 2, 5, 6, 7)],       roc_auc,       pr_auc     ))   c <- as.data.frame(c[-1, ])         colnames(c)[1] = \"Method+dataset\"   colnames(c)[8] = \"ROC-AUC\"   colnames(c)[9] = \"PR-AUC\"      c <-     c %>%     mutate(       across(.cols = -`Method+dataset`, .fns = as.numeric),       trigger = ifelse(stringr::str_detect(`Method+dataset`, \"wo\"), \"N\", \"Y\")     ) %>%     separate(`Method+dataset`, c(\"method\", \"NA_1\"), \" \", remove = TRUE) %>%     separate(NA_1, c(\"imbalance\", NA, NA)) %>%      mutate(`F2 Score` = ((1 + 2^2) * Precision * Recall) / (2^2 * Precision + Recall)) %>%      select(method, imbalance,trigger ,`F2 Score`)         return(c)    }"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"applying-the-function-to-the-datasets","dir":"Articles","previous_headings":"","what":"Applying the function to the datasets","title":"Fraud Classification with Naive Bayes","text":"function now applied datasets adjusted data imbalance using ADASYN, SMOTE, MWMOTE ROSE. brief methods: ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":""},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"adasyn","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ADASYN","title":"Fraud Classification with Naive Bayes","text":"","code":"adasyn_wo_triggers <-    naive_bayes_classifier(adasyn_wo_triggers_train,                 adasyn_wo_triggers_test) adasyn_w_triggers <-   naive_bayes_classifier(adasyn_w_triggers_train,                 adasyn_w_triggers_test)"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"smote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"SMOTE","title":"Fraud Classification with Naive Bayes","text":"","code":"smote_wo_triggers <-    naive_bayes_classifier(smote_wo_triggers_train,                 smote_wo_triggers_test) smote_w_triggers <-   naive_bayes_classifier(smote_w_triggers_train,                 smote_w_triggers_test)"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"mwmote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"MWMOTE","title":"Fraud Classification with Naive Bayes","text":"","code":"mwmote_wo_triggers <-    naive_bayes_classifier(mwmote_wo_triggers_train,                 mwmote_wo_triggers_test) mwmote_w_triggers <-   naive_bayes_classifier(mwmote_w_triggers_train,                 mwmote_w_triggers_test)"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"rose","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ROSE","title":"Fraud Classification with Naive Bayes","text":"","code":"rose_wo_triggers <-    naive_bayes_classifier(rose_wo_triggers_train,                 rose_wo_triggers_test) rose_w_triggers <-   naive_bayes_classifier(rose_w_triggers_train,                 rose_w_triggers_test)"},{"path":"/articles/05_fraud_classification_naive_bayes.html","id":"results-comparison","dir":"Articles","previous_headings":"","what":"Results comparison","title":"Fraud Classification with Naive Bayes","text":"can seen charts, models trigger fields shown better predictability compared without triggers.","code":"bind_rows(   adasyn_wo_triggers,   adasyn_w_triggers,   smote_wo_triggers,   smote_w_triggers,   mwmote_wo_triggers,   mwmote_w_triggers,   rose_wo_triggers,   rose_w_triggers ) %>%   select(imbalance, trigger, everything()) %>%    ggplot() +   geom_bar(aes(x = trigger, y = `F2 Score`, fill = trigger), stat='identity') +   facet_wrap(~imbalance)"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"improving-fit-of-a-random-forest-model","dir":"Articles","previous_headings":"","what":"Improving fit of a Random Forest model","title":"Fraud Classification with Random Forest","text":"One can add triggers standard claims dataset improve model’s predictability fraud. illustrate using random forest model vignette. data pre-processing vignette, treated data imbalance claims data using 4 different types data imbalance techniques - ADASYN, SMOTE, MWMOTE ROSE. Random Forest ensemble supervised learning algorithm used classification regression. scenario using binary classification problem. random forest algorithm way make predictions based many decision trees. creates multiple decision trees randomly selecting subsets data features. , tree trained different subset data features, new data point presented, tree predicts class label independently. Finally, predictions trees combined get final prediction. Random forest often used improve performance reduce overfitting decision trees.","code":""},{"path":"/articles/06_fraud_classification_random_forest.html","id":"importing-required-libraries","dir":"Articles","previous_headings":"","what":"Importing required libraries","title":"Fraud Classification with Random Forest","text":"","code":"library(dplyr) library(rpart) library(pROC) library(caret) library(randomForest) library(PRROC) library(tidyr) library(stringr) library(ggplot2) options(scipen=999)"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"creating-random-forest-model-function","dir":"Articles","previous_headings":"","what":"Creating random forest model function","title":"Fraud Classification with Random Forest","text":"create function implementing Random Forest model order easily apply various datasets. function takes two arguments: train dataset test dataset. response variable “fraud” variables considered predictor variables. Overall function fits Random Forest model binary classification fraud non-fraud evaluates performance using various metrics. F2 score used appropriate metric compare model-fit results. want improve identification fraud. also produces plots random forest model’s performance variable importance.","code":"random_forest <- function(data_train, data_test) {   # train the random forest model   classifier_rf <-     randomForest(fraud ~ ., data = data_train, ntree = 100)      # predict probabilities on the test set   y_prob <-     predict(classifier_rf, newdata = data_test, type = \"prob\")[, 2]      # calculate ROC AUC and PR AUC   roc_obj <- roc(data_test$fraud, y_prob)   pr_obj <-     pr.curve(scores.class0 = y_prob,              weights.class0 = ifelse(data_test$fraud == \"1\", 1, 0))      # determine threshold using ROC curve   threshold <- coords(roc_obj, \"best\")[[1]]      # classify test set based on threshold   y_pred <- ifelse(y_prob > threshold, 1, 0)      # Confusion Matrix   c1 <-     confusionMatrix(data_test$fraud,                     as.factor(y_pred),                     mode = \"everything\",                     positive = \"1\")   c <-     rbind(c1,           c(             paste0(\"RF \", deparse(substitute(data_train))),             c1$overall[1],             c1$byClass[c(1, 2, 5, 6, 7)],             roc_obj$auc,             pr_obj$auc.integral           ))      # Plotting model   plot(classifier_rf)      # Importance plot   importance(classifier_rf)      # Variable importance plot   varImpPlot(classifier_rf, top = 10)      c <- as.data.frame(c[-1, ])      colnames(c)[1] = \"Method+dataset\"   colnames(c)[8] = \"ROC-AUC\"   colnames(c)[9] = \"PR-AUC\"      c <-     c %>%     mutate(       across(.cols = -`Method+dataset`, .fns = as.numeric),       trigger = ifelse(stringr::str_detect(`Method+dataset`, \"wo\"), \"N\", \"Y\")     ) %>%     separate(`Method+dataset`, c(\"method\", \"NA_1\"), \" \", remove = TRUE) %>%     separate(NA_1, c(\"imbalance\", NA, NA)) %>%      mutate(`F2 Score` = ((1 + 2^2) * Precision * Recall) / (2^2 * Precision + Recall)) %>%      select(method, imbalance,trigger ,`F2 Score`)      return(c) }"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"applying-the-function-to-the-datasets","dir":"Articles","previous_headings":"Creating random forest model function","what":"Applying the function to the datasets","title":"Fraud Classification with Random Forest","text":"function now applied datasets adjusted data imbalance using ADASYN, SMOTE, MWMOTE ROSE. brief methods: ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":""},{"path":"/articles/06_fraud_classification_random_forest.html","id":"adasyn","dir":"Articles","previous_headings":"Creating random forest model function > Applying the function to the datasets","what":"ADASYN","title":"Fraud Classification with Random Forest","text":"","code":"adasyn_wo_triggers <-    random_forest(adasyn_wo_triggers_train,                 adasyn_wo_triggers_test) adasyn_w_triggers <-   random_forest(adasyn_w_triggers_train,                 adasyn_w_triggers_test)"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"smote","dir":"Articles","previous_headings":"Creating random forest model function > Applying the function to the datasets","what":"SMOTE","title":"Fraud Classification with Random Forest","text":"","code":"smote_wo_triggers <-    random_forest(smote_wo_triggers_train,                 smote_wo_triggers_test) smote_w_triggers <-   random_forest(smote_w_triggers_train,                 smote_w_triggers_test)"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"mwmote","dir":"Articles","previous_headings":"Creating random forest model function > Applying the function to the datasets","what":"MWMOTE","title":"Fraud Classification with Random Forest","text":"","code":"mwmote_wo_triggers <-    random_forest(mwmote_wo_triggers_train,                 mwmote_wo_triggers_test) mwmote_w_triggers <-   random_forest(mwmote_w_triggers_train,                 mwmote_w_triggers_test)"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"rose","dir":"Articles","previous_headings":"Creating random forest model function > Applying the function to the datasets","what":"ROSE","title":"Fraud Classification with Random Forest","text":"","code":"rose_wo_triggers <-    random_forest(rose_wo_triggers_train,                 rose_wo_triggers_test) rose_w_triggers <-   random_forest(rose_w_triggers_train,                 rose_w_triggers_test)"},{"path":"/articles/06_fraud_classification_random_forest.html","id":"results-comparison","dir":"Articles","previous_headings":"Creating random forest model function","what":"Results comparison","title":"Fraud Classification with Random Forest","text":"can seen charts, models trigger fields shown better predictability compared without triggers.","code":"bind_rows(   adasyn_wo_triggers,   adasyn_w_triggers,   smote_wo_triggers,   smote_w_triggers,   mwmote_wo_triggers,   mwmote_w_triggers,   rose_wo_triggers,   rose_w_triggers ) %>%   select(imbalance, trigger, everything()) %>%    ggplot() +   geom_bar(aes(x = trigger, y = `F2 Score`, fill = trigger), stat='identity') +   facet_wrap(~imbalance)"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"improving-fit-of-a-xgboost-model","dir":"Articles","previous_headings":"","what":"Improving fit of a XGBoost model","title":"Fraud Classification with XG Boost","text":"One can add triggers standard claims dataset improve model’s predictability fraud. illustrate using XGBoost model vignette. data pre-processing vignette, treated data imbalance claims data using 4 different types data imbalance techniques - ADASYN, SMOTE, MWMOTE ROSE. XGBoost supervised machine learning algorithm used regression classification problems. case using binary classification. ’s improved version Gradient Boosting Machine (GBM) ’s faster, accurate, scalable. XGBoost creates simple decision trees, calculates gradient loss function, adds regularization prevent overfitting, combines predictions trees make final prediction. XGBoost faster accurate GBM, can handle missing data, less prone overfitting, requires careful tuning hyperparameters.","code":""},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"importing-required-libraries","dir":"Articles","previous_headings":"","what":"Importing required libraries","title":"Fraud Classification with XG Boost","text":"","code":"library(dplyr) library(rpart) library(pROC) library(caret) library(xgboost) library(PRROC) library(tidyr) library(stringr) library(ggplot2) options(scipen=999)"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"creating-xg-boost-model-function","dir":"Articles","previous_headings":"","what":"Creating XG Boost model function","title":"Fraud Classification with XG Boost","text":"create function implementing XGBoost model order easily apply various datasets. function takes two arguments: train dataset test dataset response variable “fraud” variables considered predictor variables. number boosting rounds set 15 Overall function implementing XGBoost algorithm train binary classification model predict fraud non-fraud evaluates performance using various metrics. F2 score used appropriate metric compare model-fit results. want improve identification fraud. also generates plot variable importance scores.","code":"xg_boost <- function(data_train, data_test) {   dtrain <-     xgb.DMatrix(data = data.matrix(data_train %>%                                      dplyr::select(-c(fraud))),                 label = data_train$fraud)      dtest <-     xgb.DMatrix(data = data.matrix(data_test %>%                                      dplyr::select(-c(fraud))),                 label = data_test$fraud)      # Train the model   model <- xgb.train(data = dtrain, nrounds = 15)      # Use the model to make predictions on test data   pred_y <- predict(model, dtest)      # Get the ROC curve and calculate the ROC AUC   roc_obj <- roc(data_test$fraud, pred_y)   roc_auc <- auc(roc_obj)      # Get the PR curve and calculate the PR AUC   pr_obj <- pr.curve(data_test$fraud, pred_y)   pr_auc <- pr_obj$auc.integral      # Set the threshold based on the optimal ROC curve threshold   threshold <- coords(roc_obj, \"best\")[[1]]   tree.pred <- ifelse(pred_y > threshold, 1, 0)      # Confusion Matrix   c1 <-     confusionMatrix(data_test$fraud,                     as.factor(tree.pred),                     mode = \"everything\",                     positive = \"1\")   c <-     rbind(c1, c(       paste0(\"XGB \", deparse(substitute(data_train))),       c1$overall[1],       c1$byClass[c(1, 2, 5, 6, 7)],       roc_auc,       pr_auc     ))   c <- as.data.frame(c[-1, ])      colnames(c)[1] = \"Method+dataset\"   colnames(c)[8] = \"ROC-AUC\"   colnames(c)[9] = \"PR-AUC\"      c <-     c %>%     mutate(       across(.cols = -`Method+dataset`, .fns = as.numeric),       trigger = ifelse(stringr::str_detect(`Method+dataset`, \"wo\"), \"N\", \"Y\")     ) %>%     separate(`Method+dataset`, c(\"method\", \"NA_1\"), \" \", remove = TRUE) %>%     separate(NA_1, c(\"imbalance\", NA, NA)) %>%      mutate(`F2 Score` = ((1 + 2^2) * Precision * Recall) / (2^2 * Precision + Recall)) %>%      select(method, imbalance,trigger ,`F2 Score`)      xgb.plot.importance(xgb.importance(names(data_train %>% dplyr::select(-c(     \"fraud\"   ))), model = model))      return(c)    }"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"applying-the-function-to-the-datasets","dir":"Articles","previous_headings":"","what":"Applying the function to the datasets","title":"Fraud Classification with XG Boost","text":"function now applied datasets adjusted data imbalance using ADASYN, SMOTE, MWMOTE ROSE. brief methods: ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":""},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"adasyn","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ADASYN","title":"Fraud Classification with XG Boost","text":"","code":"adasyn_wo_triggers <-    xg_boost(adasyn_wo_triggers_train,                 adasyn_wo_triggers_test) adasyn_w_triggers <-   xg_boost(adasyn_w_triggers_train,                 adasyn_w_triggers_test)"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"smote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"SMOTE","title":"Fraud Classification with XG Boost","text":"","code":"smote_wo_triggers <-    xg_boost(smote_wo_triggers_train,                 smote_wo_triggers_test) smote_w_triggers <-   xg_boost(smote_w_triggers_train,                 smote_w_triggers_test)"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"mwmote","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"MWMOTE","title":"Fraud Classification with XG Boost","text":"","code":"mwmote_wo_triggers <-    xg_boost(mwmote_wo_triggers_train,                 mwmote_wo_triggers_test) mwmote_w_triggers <-   xg_boost(mwmote_w_triggers_train,                 mwmote_w_triggers_test)"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"rose","dir":"Articles","previous_headings":"Applying the function to the datasets","what":"ROSE","title":"Fraud Classification with XG Boost","text":"","code":"rose_wo_triggers <-    xg_boost(rose_wo_triggers_train,                 rose_wo_triggers_test) rose_w_triggers <-   xg_boost(rose_w_triggers_train,                 rose_w_triggers_test)"},{"path":"/articles/07_fraud_classification_xg_boost.html","id":"results-comparison","dir":"Articles","previous_headings":"","what":"Results comparison","title":"Fraud Classification with XG Boost","text":"can seen charts, models trigger fields shown better predictability compared without triggers.","code":"bind_rows(   adasyn_wo_triggers,   adasyn_w_triggers,   smote_wo_triggers,   smote_w_triggers,   mwmote_wo_triggers,   mwmote_w_triggers,   rose_wo_triggers,   rose_w_triggers ) %>%   select(imbalance, trigger, everything()) %>%    ggplot() +   geom_bar(aes(x = trigger, y = `F2 Score`, fill = trigger), stat='identity') +   facet_wrap(~imbalance)"},{"path":"/articles/SSSIHLCASFraudClassifyR.html","id":"what-is-health-insurance-fraud","dir":"Articles","previous_headings":"","what":"What is Health Insurance Fraud","title":"Health Insurance Fraud classification with Triggers","text":"Fraud detection important area research healthcare systems due financial consequences arising mainly investigation costs, revenue losses, reputational risk. Healthcare fraud can broadly classified three categories: Provider fraud: Provider healthcare fraud may committed individuals (e.g., physicians, doctors) organizations (e.g., hospitals). Sometimes provider fraud may also involve service providers individuals (e.g., patients). Customer fraud: Customer fraud may committed insured/ consumer knowingly misrepresents facts get additional benefits. may work union healthcare providers (e.g., doctors, physicians) Insurer fraud: Insurer fraud may committed insurance company company’s employees work union parties reduce claim payouts consumers look provider fraud customer fraud relatively possible find data .","code":""},{"path":"/articles/SSSIHLCASFraudClassifyR.html","id":"fraud-classification---role-of-machine-learning","dir":"Articles","previous_headings":"","what":"Fraud classification - role of machine learning","title":"Health Insurance Fraud classification with Triggers","text":"Traditional healthcare fraud detection models heavily dependent auditing expert inspection. models costly, inefficient, time-consuming require lots human intervention. Often thousands records handled claims handlers expected review claims. circumstances, focus special characteristics claims pay little attention relationships features. Various machine learning deep learning models can used healthcare systems efficient fraud detection. appropriately training algorithm pick patterns characteristic fraudulent claims, machine learning models often proven useful, cost-efficient ways embed traditional fraud classification processes.","code":""},{"path":"/articles/SSSIHLCASFraudClassifyR.html","id":"data-imbalance-problem","dir":"Articles","previous_headings":"","what":"Data Imbalance problem","title":"Health Insurance Fraud classification with Triggers","text":"Fraud classification generally 2-class problem statement .e. claim can classified either fraud non-fraud. Often, 2-class problem data distorted towards one classes. typical claims data set, one can expect fraudulent claims small percentage total claims. Training machine learning model data set lead us predict non-fraud cases accurately compared fraud cases. However, practice, generally preferred detect fraud cases correctly rather non-fraud cases. various methods adjust imbalance either generating synthetic data points minority class (-sampling) reduce majority class observations (-sampling) package vignettes, illustrated data without triggers can balanced using techniques. - ADASYN(Adaptive Synthetic Sampling) generates synthetic data points minority class imbalanced datasets, creating samples underrepresented regions improve model performance. - SMOTE (Synthetic Minority -sampling Technique) generates synthetic data points minority class imbalanced datasets interpolating minority class examples create new samples. - MWMOTE(Majority Weighted Minority Oversampling Technique) modification SMOTE aims address issue noisy examples adding weighting factor minority class example based level noise. - ROSE (Random -Sampling Examples) generates synthetic data points minority class randomly selecting sample minority class.","code":""},{"path":"/articles/SSSIHLCASFraudClassifyR.html","id":"using-triggers-to-improve-ml-predictability","dir":"Articles","previous_headings":"","what":"Using triggers to improve ML predictability","title":"Health Insurance Fraud classification with Triggers","text":"Actuarial rule-based triggers can effectively used identify suspicious claims. However, can introduced engineered features machine learning models improve predictability. ML models can also used identify triggers effective classifying fraud can -turn help improving existing systems insurer.","code":""},{"path":"/articles/SSSIHLCASFraudClassifyR.html","id":"package-vignettes","dir":"Articles","previous_headings":"","what":"Package Vignettes","title":"Health Insurance Fraud classification with Triggers","text":"performed model fitting health insurance claims data set (sample included package). model fitting process explained using vignettes: Data Pre-Processing: Pre-processing claims data adjusting imbalance Mapping Triggers Data: Adding triggers claims data using package. Pre-processing data set adjusting imbalance. Fraud classification using machine learning models: Machine learning models fit data sets - without triggers generated . Decision Trees (DT) Generalized Linear Model (GLM) Naive-Bayes (NB) Random Forest (RF) XGBoost (XGB) consolidated visualization results . can see majority cases, models trigger variables show better F-2 scores perform better fraud classification.","code":"library(dplyr) library(ggplot2) results %>%    ggplot()+   geom_bar(     aes(       x = imbalance,       y = F2,       fill = trigger       ),      position = \"dodge\",      stat = \"identity\"     )+   facet_wrap(~method)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"SSSIHL -DMACS. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"-DMACS S (2023). SSSIHLCASFraudClassifyR: Use Triggers Improve Fraud Classification. R package version 0.1.0.","code":"@Manual{,   title = {SSSIHLCASFraudClassifyR: Use Triggers to Improve Fraud Classification},   author = {SSSIHL -DMACS},   year = {2023},   note = {R package version 0.1.0}, }"},{"path":"/index.html","id":"sssihlcasfraudclassifyr-","dir":"","previous_headings":"","what":"Use Triggers to Improve Fraud Classification","title":"Use Triggers to Improve Fraud Classification","text":"SSSIHLCASFraudClassifyR one outputs 2022 CAS( Casualty Actuarial Society) Individual Grant Award Project. objective project provide framework actuarial inputs can integrated Machine Learning models improve fraud detection importantly, make business sense outcomes. package contains various functions add flags claims data based different criteria. flags can turn used users inputs statistical machine learning models. short, infuse actuarial/insurance/behavioral triggers feature engineering step model development. find various vignettes package illustrate model fitting process quantify improvement model fit due addition triggers.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Use Triggers to Improve Fraud Classification","text":"can install development version SSSIHLCASFraudClassifyR like :","code":"# FILL THIS IN! HOW CAN PEOPLE INSTALL YOUR DEV PACKAGE?"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Use Triggers to Improve Fraud Classification","text":"basic example adding fraud trigger claims data using package. Claim amount trigger ratio actual paid claim amount procedure amount. cashless claims, cost procedure often agreed insurer medical service provider upfront. claims ratio higher 1, must investigated understand reasons. indication fraud medical service provider - medical service provider levied additional charges procedure otherwise required agreed contractually. map triggers data, fields can used explanatory variables fraud detection classification models. package vignettes, demonstrated triggers can added health insurance data significantly improve predictability various Machine learning Statistical models.","code":"library(SSSIHLCASFraudClassifyR) library(dplyr) #> Warning: package 'dplyr' was built under R version 4.2.3 #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  data(\"claims_data_sample\") data(\"trigger_data\") ## basic example code  claims_data_sample <-   claim_amount_trigger_map(     claims_file = claims_data_sample,     claim_paid_field = \"approved_allowed_amount\",     triggers_file = trigger_data,     procedure_code = \"primary_procedure_code\",     procedure_amount_field = \"package_amount_trigger\"   ) summary(claims_data_sample$claim_amount_ratio) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.07627 0.72000 0.96000 1.00396 1.30120 5.38200"},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 SSSIHLCASFraudClassifyR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/reference/age_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Age-based fraud trigger — age_trigger_map","title":"Age-based fraud trigger — age_trigger_map","text":"triggers file contains reasonable age ranges getting certain medical procedure done. function creates flag identify claimants whose age falls outside range.              age specified consistently claims_file triggers_file function work.","code":""},{"path":"/reference/age_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Age-based fraud trigger — age_trigger_map","text":"","code":"age_trigger_map(   claims_file,   age_column_name,   triggers_file,   procedure_code,   lower_age_limit,   upper_age_limit )"},{"path":"/reference/age_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Age-based fraud trigger — age_trigger_map","text":"claims_file data set containing claim-level information age_column_name column within claims file indicates age policy holder triggers_file file containing age ranges procedure code procedure_code column triggers_file contains code/identifier medical procedure lower_age_limit column triggers_file contains lower age limit getting procedure done upper_age_limit column triggers_file contains upper age limit getting procedure done","code":""},{"path":"/reference/age_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Age-based fraud trigger — age_trigger_map","text":"input claims_file age_flag column","code":""},{"path":"/reference/age_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Age-based fraud trigger — age_trigger_map","text":"","code":"library(dplyr) #> Warning: package 'dplyr' was built under R version 4.2.3 #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union data(claims_data_sample) data(trigger_data)  age_trigger_map( claims_file = claims_data_sample, age_column_name = \"patient_age\", triggers_file = trigger_data, lower_age_limit = \"lower_age_limit\", upper_age_limit = \"upper_age_limit\", procedure_code = \"primary_procedure_code\") %>% group_by(patient_age) %>% summarise(age_flag = mean(age_flag)) #> # A tibble: 82 × 2 #>    patient_age age_flag #>          <dbl>    <dbl> #>  1           2        0 #>  2           3        0 #>  3           4        0 #>  4           5        0 #>  5           6        0 #>  6           7        0 #>  7           8        0 #>  8           9        0 #>  9          10        0 #> 10          11        0 #> # ℹ 72 more rows"},{"path":"/reference/claims_data_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Claims data file — claims_data_sample","title":"Sample Claims data file — claims_data_sample","text":"Sample claims dataset containing different fields","code":""},{"path":"/reference/claims_data_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Claims data file — claims_data_sample","text":"","code":"claims_data_sample"},{"path":"/reference/claims_data_sample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample Claims data file — claims_data_sample","text":"`claims_data_sample`","code":""},{"path":"/reference/claim_amount_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"claim amount-based fraud trigger — claim_amount_trigger_map","title":"claim amount-based fraud trigger — claim_amount_trigger_map","text":"procedure specific amount generally agreed insurer medical service provider. especially case cashless claim processing. claim amount higher agreed procedure specific amount raise flag.","code":""},{"path":"/reference/claim_amount_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"claim amount-based fraud trigger — claim_amount_trigger_map","text":"","code":"claim_amount_trigger_map(   claims_file,   claim_paid_field,   triggers_file,   procedure_code,   procedure_amount_field )"},{"path":"/reference/claim_amount_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"claim amount-based fraud trigger — claim_amount_trigger_map","text":"claims_file data set containing claim-level information claim_paid_field column claims_file contains claim amount paid insurer triggers_file file containing agreed specific amount procedure procedure_code column triggers_file contains code/identifier medical procedure procedure_amount_field column triggers_file contains agreed specific amount procedure","code":""},{"path":"/reference/claim_amount_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"claim amount-based fraud trigger — claim_amount_trigger_map","text":"input claims_file claim_amount_ratio claim_amount_flag columns","code":""},{"path":"/reference/claim_amount_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"claim amount-based fraud trigger — claim_amount_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(trigger_data)  claim_amount_trigger_map( claims_file = claims_data_sample, claim_paid_field = \"approved_allowed_amount\", triggers_file = trigger_data, procedure_code = \"primary_procedure_code\", procedure_amount_field = \"package_amount_trigger\") %>% select(c(\"approved_allowed_amount\", \"claim_amount_ratio\", \"claim_amount_flag\")) #> # A tibble: 1,000 × 3 #>    approved_allowed_amount claim_amount_ratio claim_amount_flag #>                      <dbl>              <dbl>             <dbl> #>  1                   15300              1.99                  1 #>  2                   13500              1.8                   1 #>  3                   16200              0.814                 1 #>  4                   10800              1.17                  1 #>  5                    5400              0.651                 1 #>  6                   23400              0.992                 1 #>  7                   10800              0.543                 1 #>  8                   16200              1.95                  1 #>  9                   10800              1.44                  1 #> 10                    1800              0.196                 1 #> # ℹ 990 more rows"},{"path":"/reference/claim_count_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Claim count-based fraud trigger — claim_count_trigger_map","title":"Claim count-based fraud trigger — claim_count_trigger_map","text":"expect policyholder get given medical treatment times year, depending nature treatment. policy holder taken given treatment unreasonably high number times, needs investigated fraud. function identifies policyholders.","code":""},{"path":"/reference/claim_count_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Claim count-based fraud trigger — claim_count_trigger_map","text":"","code":"claim_count_trigger_map(   claim_count,   claim_count_pa,   claim_count_trigger_file,   procedure_code_field,   claim_count_trigger )"},{"path":"/reference/claim_count_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Claim count-based fraud trigger — claim_count_trigger_map","text":"claim_count file contains total number times policy holder claimed given procedure given time period claim_count_pa column contains total number claims per year policy holder claim_count_trigger_file file containing maximum number  times policy holder can claim procedure procedure_code_field column claim_count_trigger_file contains code/identifier medical procedure claim_count_trigger column claim_count_trigger_file indicates number times procedure can claimed policyholder can considered potential fraud","code":""},{"path":"/reference/claim_count_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Claim count-based fraud trigger — claim_count_trigger_map","text":"input claims_file claim_count_flag column","code":""},{"path":"/reference/claim_count_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Claim count-based fraud trigger — claim_count_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(trigger_data)  claim_count_trigger_map( claim_count = claims_data_sample, claim_count_pa = \"claim_count_pa\", claim_count_trigger_file = trigger_data, procedure_code_field = \"primary_procedure_code\", claim_count_trigger = \"claim_count_trigger\") %>% group_by(claim_count_pa)%>% summarise(claim_count_flag = mean(claim_count_flag)) #> # A tibble: 32 × 2 #>    claim_count_pa claim_count_flag #>             <dbl>            <dbl> #>  1              1            0     #>  2              2            0.140 #>  3              3            0.138 #>  4              4            0.231 #>  5              5            0.333 #>  6              6            0.2   #>  7              7            0     #>  8              8            0     #>  9             10            0     #> 10             11            0.667 #> # ℹ 22 more rows"},{"path":"/reference/claim_reported_delay_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"claim reporting delay based fraud trigger — claim_reported_delay_trigger_map","title":"claim reporting delay based fraud trigger — claim_reported_delay_trigger_map","text":"policy treatment start date treatment end date. claim reported within permissible days treatment end date(discharge). claim reported date outside permissible limit raise flag","code":""},{"path":"/reference/claim_reported_delay_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"claim reporting delay based fraud trigger — claim_reported_delay_trigger_map","text":"","code":"claim_reported_delay_trigger_map(   claims_file,   treatment_end_date_field,   claim_reported_date_field,   claim_delay_days )"},{"path":"/reference/claim_reported_delay_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"claim reporting delay based fraud trigger — claim_reported_delay_trigger_map","text":"claims_file data set containing claim-level information treatment_end_date_field column claims_file contains ending date treatment claim_reported_date_field column claims_file contains claim reported date policy claim_delay_days user input sets permissible time period within claim reported","code":""},{"path":"/reference/claim_reported_delay_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"claim reporting delay based fraud trigger — claim_reported_delay_trigger_map","text":"input claims_file claims_delay_flag column","code":""},{"path":"/reference/claim_reported_delay_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"claim reporting delay based fraud trigger — claim_reported_delay_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample)  claim_reported_delay_trigger_map( claims_file = claims_data_sample, treatment_end_date_field = \"treatment_end_date\", claim_reported_date_field = \"claim_reported_date\", claim_delay_days = 15) %>% select(c(\"treatment_end_date\", \"claim_reported_date\", \"claim_reported_delay_flag\")) #> # A tibble: 1,000 × 3 #>    treatment_end_date claim_reported_date claim_reported_delay_flag #>    <date>             <date>                                  <dbl> #>  1 2019-09-04         2019-09-04                                  0 #>  2 2019-09-04         2019-09-04                                  0 #>  3 2019-09-04         2019-09-04                                  0 #>  4 2019-09-05         2019-09-05                                  0 #>  5 2019-08-24         2019-08-26                                  0 #>  6 2019-12-08         2019-12-08                                  0 #>  7 2020-01-14         2020-01-14                                  0 #>  8 2020-01-24         2020-01-24                                  0 #>  9 2019-08-30         2019-08-30                                  0 #> 10 2019-09-02         2019-09-02                                  0 #> # ℹ 990 more rows"},{"path":"/reference/close_prox_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Close proximity-based fraud trigger — close_prox_trigger_map","title":"Close proximity-based fraud trigger — close_prox_trigger_map","text":"claim close proximity treatment start date close policy commencement date. function  raise flag claims.","code":""},{"path":"/reference/close_prox_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Close proximity-based fraud trigger — close_prox_trigger_map","text":"","code":"close_prox_trigger_map(   claims_file,   treatment_start_date,   policy_commencement_date,   triggers_file,   procedure_code,   close_prox_days )"},{"path":"/reference/close_prox_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Close proximity-based fraud trigger — close_prox_trigger_map","text":"claims_file data set containing claim-level information treatment_start_date column claims_file contains starting date treatment policy_commencement_date column claims_file contains commencement date policy triggers_file file containing number days procedure within can call close proximity claim procedure_code column triggers_file contains code/identifier medical procedure close_prox_days column triggers_file contains number days procedure within can call close proximity claim","code":""},{"path":"/reference/close_prox_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Close proximity-based fraud trigger — close_prox_trigger_map","text":"input claims_file close_prox_flag claim_duration_days columns","code":""},{"path":"/reference/close_prox_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Close proximity-based fraud trigger — close_prox_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(trigger_data)  close_prox_trigger_map( claims_file = claims_data_sample, treatment_start_date = \"treatment_start_date\", policy_commencement_date = \"policy_commencement_date\", triggers_file = trigger_data, procedure_code = \"primary_procedure_code\", close_prox_days = \"close_prox_days\") %>% select(c(\"treatment_start_date\", \"policy_commencement_date\", \"claim_duration_days\", \"close_prox_flag\")) #> # A tibble: 1,000 × 4 #>    treatment_start_date policy_commencement_date claim_duration_days #>    <date>               <date>                   <drtn>              #>  1 2019-08-31           2019-08-20                11 days            #>  2 2019-08-31           2019-08-20                11 days            #>  3 2019-09-03           2019-08-20                14 days            #>  4 2019-09-03           2019-08-20                14 days            #>  5 2019-08-22           2019-08-20                 2 days            #>  6 2019-11-28           2019-08-20               100 days            #>  7 2020-01-12           2019-08-20               145 days            #>  8 2020-01-16           2019-08-20               149 days            #>  9 2019-08-27           2019-08-20                 7 days            #> 10 2019-09-01           2019-08-20                12 days            #> # ℹ 990 more rows #> # ℹ 1 more variable: close_prox_flag <dbl>"},{"path":"/reference/gender_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Gender-based fraud trigger — gender_trigger_map","title":"Gender-based fraud trigger — gender_trigger_map","text":"procedures gender specific. function creates red flag procedure performed claimant wrong gender. example gynacologic procedure male claimant raise redflag.              gender specified consistently claims_file triggers_file function work.","code":""},{"path":"/reference/gender_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gender-based fraud trigger — gender_trigger_map","text":"","code":"gender_trigger_map(   claims_file,   gender_column_name,   triggers_file,   procedure_code,   gender_trigger )"},{"path":"/reference/gender_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gender-based fraud trigger — gender_trigger_map","text":"claims_file data set containing claim-level information gender_column_name column claims_file contains gender policy holder triggers_file file containing gender specification procedure code procedure_code column triggers_file contains code/identifier medical procedure gender_trigger column triggers_file contains specification gender medical procedure","code":""},{"path":"/reference/gender_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gender-based fraud trigger — gender_trigger_map","text":"input claims_file gender_flag column","code":""},{"path":"/reference/gender_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gender-based fraud trigger — gender_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(trigger_data)  gender_trigger_map( claims_file = claims_data_sample, gender_column_name = \"gender_code\", triggers_file = trigger_data, procedure_code = \"primary_procedure_code\", gender_trigger = \"gender_trigger\") %>% group_by(gender_code)%>% summarise(gender_flag = mean(gender_flag)) #> # A tibble: 2 × 2 #>   gender_code gender_flag #>   <chr>             <dbl> #> 1 Female           0      #> 2 Male             0.0494"},{"path":"/reference/hospital_distance_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Hospital distance-based fraud trigger — hospital_distance_trigger_map","title":"Hospital distance-based fraud trigger — hospital_distance_trigger_map","text":"reasonable expect policyholder gets treated nearest hospital. distance residence location hospital location defined threshold, function raise flag","code":""},{"path":"/reference/hospital_distance_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hospital distance-based fraud trigger — hospital_distance_trigger_map","text":"","code":"hospital_distance_trigger_map(   claims_file,   residence_location_field,   hospital_location_field,   hospital_distance_file,   residence_location_map,   hospital_location_map,   hospital_distance_field,   distance_threshold )"},{"path":"/reference/hospital_distance_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hospital distance-based fraud trigger — hospital_distance_trigger_map","text":"claims_file data set containing claim-level information residence_location_field column claims_file location policy holder hospital_location_field column claims_file location hospital hospital_distance_file file reference table distances places data residence_location_map column hospital_distance_file  list possible residence locations hospital_location_map column hospital_distance_file possible hospital locations hospital_distance_field column hospital_distance_file contains distance hospital location residence location distance_threshold distance level beyond claim flagged fraud","code":""},{"path":"/reference/hospital_distance_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hospital distance-based fraud trigger — hospital_distance_trigger_map","text":"input claims_file hospital_distance_flag column","code":""},{"path":"/reference/hospital_distance_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hospital distance-based fraud trigger — hospital_distance_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(location_distance)  hospital_distance_trigger_map( claims_file = claims_data_sample, residence_location_field = \"residence_location\", hospital_location_field = \"hospital_location\", hospital_distance_file = location_distance, residence_location_map = \"location_1\", hospital_location_map = \"location_2\", hospital_distance_field = \"distance\", distance_threshold = 100) %>% select(c(\"residence_location\", \"hospital_location\", \"hospital_distance_flag\")) #> # A tibble: 1,000 × 3 #>    residence_location hospital_location hospital_distance_flag #>    <chr>              <chr>                              <dbl> #>  1 location1          location1                              0 #>  2 location2          location2                              0 #>  3 location1          location1                              0 #>  4 location3          location3                              0 #>  5 location4          location4                              0 #>  6 location3          location3                              0 #>  7 location5          location5                              0 #>  8 location2          location2                              0 #>  9 location6          location6                              0 #> 10 location7          location5                              0 #> # ℹ 990 more rows"},{"path":"/reference/hospital_empanelled_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Empanelled hospitals(medical service providers)-based fraud trigger — hospital_empanelled_trigger_map","title":"Empanelled hospitals(medical service providers)-based fraud trigger — hospital_empanelled_trigger_map","text":"insurer generally empanells hospitals service policy holders. process empanelment insurer ensures hospital required facilities also agrees tarrif treatments. hospital mentioned part empanelled list hospitals raise flag","code":""},{"path":"/reference/hospital_empanelled_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empanelled hospitals(medical service providers)-based fraud trigger — hospital_empanelled_trigger_map","text":"","code":"hospital_empanelled_trigger_map(   claims_file,   hospital_id_field,   empanelled_hospitals_list,   empanelled_hospital_id )"},{"path":"/reference/hospital_empanelled_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empanelled hospitals(medical service providers)-based fraud trigger — hospital_empanelled_trigger_map","text":"claims_file data set containing claim-level information hospital_id_field column unique identity number hospitals empanelled_hospitals_list file containing list empanelled hospitals empanelled_hospital_id column empanelled_hospital_list file contains unique hospital ids","code":""},{"path":"/reference/hospital_empanelled_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empanelled hospitals(medical service providers)-based fraud trigger — hospital_empanelled_trigger_map","text":"input claims_file hospital_empanelled_flag column","code":""},{"path":"/reference/hospital_empanelled_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empanelled hospitals(medical service providers)-based fraud trigger — hospital_empanelled_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(hospital_list)  hospital_empanelled_trigger_map( claims_file = claims_data_sample, hospital_id_field = \"medical_service_provider_id\", empanelled_hospitals_list = hospital_list, empanelled_hospital_id = \"hosp_id\") %>% group_by(medical_service_provider_id)%>% summarise(hospital_empanelled_flag = mean(hospital_empanelled_flag)) #> # A tibble: 215 × 2 #>    medical_service_provider_id hospital_empanelled_flag #>    <chr>                                          <dbl> #>  1 hospital1                                          0 #>  2 hospital10                                         0 #>  3 hospital100                                        0 #>  4 hospital101                                        0 #>  5 hospital102                                        0 #>  6 hospital103                                        0 #>  7 hospital104                                        0 #>  8 hospital105                                        0 #>  9 hospital106                                        0 #> 10 hospital107                                        0 #> # ℹ 205 more rows"},{"path":"/reference/hospital_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Hospital List data — hospital_list","title":"Hospital List data — hospital_list","text":"List hospitals cashless claims","code":""},{"path":"/reference/hospital_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hospital List data — hospital_list","text":"","code":"hospital_list"},{"path":"/reference/hospital_list.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hospital List data — hospital_list","text":"`hospital_list`","code":""},{"path":"/reference/hosp_days_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Hospital admitted days-based fraud trigger — hosp_days_trigger_map","title":"Hospital admitted days-based fraud trigger — hosp_days_trigger_map","text":"procedure reasonable number days claimant admitted hospital.number days actually admitted higher reasonable procedure function raise flag.","code":""},{"path":"/reference/hosp_days_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hospital admitted days-based fraud trigger — hosp_days_trigger_map","text":"","code":"hosp_days_trigger_map(   claims_file,   no_of_days_stayed,   triggers_file,   procedure_code,   admission_days_trigger )"},{"path":"/reference/hosp_days_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hospital admitted days-based fraud trigger — hosp_days_trigger_map","text":"claims_file data set containing claim-level information no_of_days_stayed column claims_file contains number days actually admitted hospital triggers_file file containing reasonable number days claimant admitted hospital procedure procedure_code column triggers_file contains code/identifier medical procedure admission_days_trigger column triggers_file contains reasonable number days claimant admitted hospital procedure","code":""},{"path":"/reference/hosp_days_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hospital admitted days-based fraud trigger — hosp_days_trigger_map","text":"input claims_file no_days_ratio hosp_days_flag columns","code":""},{"path":"/reference/hosp_days_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hospital admitted days-based fraud trigger — hosp_days_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample) data(trigger_data)  hosp_days_trigger_map( claims_file = claims_data_sample, no_of_days_stayed = \"no_of_days_stayed\", triggers_file = trigger_data, procedure_code = \"primary_procedure_code\", admission_days_trigger = \"admission_days_trigger\") %>% select(c(\"no_of_days_stayed\", \"admission_days_trigger\", \"hosp_days_flag\")) #> # A tibble: 1,000 × 3 #>    no_of_days_stayed admission_days_trigger hosp_days_flag #>                <dbl>                  <dbl>          <dbl> #>  1                 5                      0              1 #>  2                 5                      0              1 #>  3                 2                      0              1 #>  4                 3                      0              1 #>  5                 3                      0              1 #>  6                11                      0              1 #>  7                 3                      0              1 #>  8                 9                      0              1 #>  9                 4                      0              1 #> 10                 2                      0              1 #> # ℹ 990 more rows"},{"path":"/reference/location_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Location Distance Data — location_distance","title":"Location Distance Data — location_distance","text":"Distances two locations used triggers","code":""},{"path":"/reference/location_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Location Distance Data — location_distance","text":"","code":"location_distance"},{"path":"/reference/location_distance.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Location Distance Data — location_distance","text":"`location_distance`","code":""},{"path":"/reference/treatment_date_validity_trigger_map.html","id":null,"dir":"Reference","previous_headings":"","what":"treatment date validity-based fraud trigger — treatment_date_validity_trigger_map","title":"treatment date validity-based fraud trigger — treatment_date_validity_trigger_map","text":"policy commencement termination date within claim event(treatment) occur. treatment date outside dates raise flag","code":""},{"path":"/reference/treatment_date_validity_trigger_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"treatment date validity-based fraud trigger — treatment_date_validity_trigger_map","text":"","code":"treatment_date_validity_trigger_map(   claims_file,   treatment_start_date_field,   policy_commencement_date_field,   policy_termination_date_field )"},{"path":"/reference/treatment_date_validity_trigger_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"treatment date validity-based fraud trigger — treatment_date_validity_trigger_map","text":"claims_file data set containing claim-level information treatment_start_date_field column claims_file contains starting date treatment policy_commencement_date_field column claims_file contains commencement date policy policy_termination_date_field column claims_file contains termination date policy","code":""},{"path":"/reference/treatment_date_validity_trigger_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"treatment date validity-based fraud trigger — treatment_date_validity_trigger_map","text":"input claims_file treatment_date_validity_flag column","code":""},{"path":"/reference/treatment_date_validity_trigger_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"treatment date validity-based fraud trigger — treatment_date_validity_trigger_map","text":"","code":"library(dplyr)  data(claims_data_sample)  treatment_date_validity_trigger_map( claims_file = claims_data_sample, treatment_start_date_field = \"treatment_start_date\", policy_commencement_date_field = \"policy_commencement_date\", policy_termination_date_field = \"policy_termination_date\") %>% select(c(\"treatment_start_date\", \"policy_commencement_date\", \"treatment_date_validity_flag\")) #> # A tibble: 1,000 × 3 #>    treatment_start_date policy_commencement_date treatment_date_validity_flag #>    <date>               <date>                                          <dbl> #>  1 2019-08-31           2019-08-20                                          0 #>  2 2019-08-31           2019-08-20                                          0 #>  3 2019-09-03           2019-08-20                                          0 #>  4 2019-09-03           2019-08-20                                          0 #>  5 2019-08-22           2019-08-20                                          0 #>  6 2019-11-28           2019-08-20                                          0 #>  7 2020-01-12           2019-08-20                                          0 #>  8 2020-01-16           2019-08-20                                          0 #>  9 2019-08-27           2019-08-20                                          0 #> 10 2019-09-01           2019-08-20                                          0 #> # ℹ 990 more rows"},{"path":"/reference/trigger_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Triggers file — trigger_data","title":"Triggers file — trigger_data","text":"File containing different triggers","code":""},{"path":"/reference/trigger_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triggers file — trigger_data","text":"","code":"trigger_data"},{"path":"/reference/trigger_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Triggers file — trigger_data","text":"`trigger_data`","code":""}]
